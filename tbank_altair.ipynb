{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"IlyaGusev/ru_turbo_saiga\")"
      ],
      "metadata": {
        "id": "IBrja0DbxKfW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"t-tech/T-pro-it-1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "nFIwNQKexOJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "oT_GhUib0CGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig, SFTTrainer, TrainingArguments\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = []\n",
        "    for messages in examples['messages']:\n",
        "        conversation = \"\"\n",
        "        for message in messages:\n",
        "            conversation += f\"{message['role']}: {message['content']}\\n\"\n",
        "        inputs.append(conversation)\n",
        "    return tokenizer(inputs, truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "ready = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        "    num_train_epochs=3,\n",
        "    report_to=[\"tensorboard\"]\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=ready[\"train\"],\n",
        "    eval_dataset=ready[\"validation\"],\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "WpfGRtgnyw9T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}